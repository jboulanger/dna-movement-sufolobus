{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process all files\n",
    "\n",
    "In this notebook, we load the list of files to process them in parallel.\n",
    "The results are saved into a hdf5 file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# list files from the src folder\n",
    "src = Path('/media/cephfs2/jparham/Joe for Jerome /')\n",
    "dst = Path('/media/cephfs2/jeromeb/userdata/Baum_group/jparham/Analysis8')\n",
    "\n",
    "filelist = pd.read_csv(dst/'filelist.csv', index_col=0)\n",
    "print(f\"Number of files {len(filelist)}\")\n",
    "filelist.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing\n",
    "\n",
    "Files are processed in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import motionquant as mq\n",
    "import dask\n",
    "from dask.distributed import Lock\n",
    "import traceback\n",
    "\n",
    "def process(filename, results_path, lock=None):\n",
    "    \"\"\"Process files and save results in a hf5 file\"\"\"\n",
    "    name = Path(filename).stem        \n",
    "    img, cell_mask, cell_trj, diff, flow, rho, div, blob_labels, blobs_trj = mq.process(Path(filename))\n",
    "    if lock is not None:\n",
    "        lock.acquire()\n",
    "    mq.save_result(results_path, name, img, cell_mask, cell_trj, diff, flow, rho, div, blob_labels, blobs_trj)\n",
    "    if lock is not None:\n",
    "        lock.release()\n",
    "    df = mq.record(filename, img, cell_mask, cell_trj, diff, flow, rho, div, blob_labels, blobs_trj)\n",
    "    return df\n",
    "\n",
    "def process_safe(filename, results_path):\n",
    "    \"\"\"Process files catching exceptions\"\"\"\n",
    "    try:\n",
    "        return process(filename, results_path)\n",
    "    except Exception as e:\n",
    "        print(f\"file '{filename}' could not be processed\")\n",
    "        print(e)\n",
    "        print(traceback.print_exc())\n",
    "        pass\n",
    "   \n",
    "\n",
    "results_path = dst/Path('results.h5') # result\n",
    "if results_path.exists():\n",
    "    results_path.unlink()\n",
    "\n",
    "print(f\"Saving results in file '{results_path}'\")\n",
    "parallel_processing = False\n",
    "if parallel_processing:\n",
    "    from dask.distributed import LocalCluster\n",
    "    cluster = LocalCluster()\n",
    "    client = cluster.get_client()\n",
    "    cluster.scale(2)\n",
    "    print(cluster)\n",
    "    lock = Lock('process-sufo')\n",
    "    tsk = [dask.delayed(process_safe)(filename, results_path, lock) for filename in filelist['path'].iloc]\n",
    "    res = dask.compute(tsk)\n",
    "    df = pd.concat(res[0])\n",
    "else:\n",
    "    df = pd.concat(process_safe(filename, results_path) for filename in filelist['path'].iloc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(dst/'results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
